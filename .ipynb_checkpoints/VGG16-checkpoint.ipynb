{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import inspect\n",
    "import sys\n",
    "import pygame\n",
    "\n",
    "#serve per fare la progress bar del download\n",
    "from clint.textui import progress\n",
    "#serve per effetturare richieste http\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOWNLOAD MODELLO VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"modello\"):\n",
    "    os.makedirs(\"modello\")\n",
    "\n",
    "percorso = \"modello/vgg16.tfmodel\"\n",
    "\n",
    "if os.path.isfile(percorso):\n",
    "    print(\"Modello già scaricato.\")\n",
    "\n",
    "else:\n",
    "    url_modello = \"https://s3.amazonaws.com/cadl/models/vgg16.tfmodel\"\n",
    "\n",
    "    richiesta = requests.get(url_modello, stream=True)\n",
    "    with open(percorso, \"wb\") as file:\n",
    "        lunghezza_totale = int(richiesta.headers.get('content-length'))\n",
    "        for chunk in progress.mill(richiesta.iter_content(chunk_size=1024), expected_size=(lunghezza_totale/1024) + 1):\n",
    "            if chunk:\n",
    "                file.write(chunk)\n",
    "                file.flush()\n",
    "    print(\"Modello scaricato con successo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSE VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16:\n",
    "    \n",
    "    nome_tensore_immagine_input = \"images:0\"\n",
    "    \n",
    "    #Strati convoluzionali da utilizzare ai fini dello Style Transfer\n",
    "    nomi_strati = ['conv1_1/conv1_1', 'conv1_2/conv1_2',\n",
    "                   'conv2_1/conv2_1', 'conv2_2/conv2_2',\n",
    "                   'conv3_1/conv3_1', 'conv3_2/conv3_2', 'conv3_3/conv3_3',\n",
    "                   'conv4_1/conv4_1', 'conv4_2/conv4_2', 'conv4_3/conv4_3',\n",
    "                   'conv5_1/conv5_1', 'conv5_2/conv5_2', 'conv5_3/conv5_3']\n",
    "    \n",
    "    #costruttore\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.graph = tf.Graph()\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "            \n",
    "            #apre il file precedentemente scaricato\n",
    "            with tf.gfile.FastGFile(percorso, 'rb') as file:\n",
    "                \n",
    "                #copia di un grafo di tensorflow, inizialmente vuoto\n",
    "                graph_def = tf.GraphDef()\n",
    "                \n",
    "                #viene aggiornata con il grafo del modello VGG16\n",
    "                graph_def.ParseFromString(file.read())\n",
    "                \n",
    "                #infine viene importato sul grafo di default\n",
    "                tf.import_graph_def(graph_def, name='')\n",
    "                \n",
    "            #ottiene un riferimento al tensore per dare in input le immagini al grafo\n",
    "            self.input = self.graph.get_tensor_by_name(self.nome_tensore_immagine_input)\n",
    "            \n",
    "            #ottiene riferimenti ai tensori per gli strati convoluzionali presi in considerazione\n",
    "            self.tensori_strati = [self.graph.get_tensor_by_name(nome + \":0\") for nome in self.nomi_strati]\n",
    "            \n",
    "    def get_tensori_strati(self, id_strati):\n",
    "        \n",
    "        return [self.tensori_strati[indice] for indice in id_strati]\n",
    "    \n",
    "    def crea_feed_dict(self, immagine):\n",
    "        #feed_dict contenente l'immagine da passare al grafo\n",
    "        \n",
    "        #VGG16 è stata progettata per prendere più immagini per input, è necessario\n",
    "        #quindi aggiungere una dimensione alla terna che abbiamo inizialmente\n",
    "        immagine = np.expand_dims(immagine, axis=0)\n",
    "        \n",
    "        feed_dict = {self.nome_tensore_immagine_input: immagine}\n",
    "        \n",
    "        return feed_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANIPOLAZIONE IMMAGINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carica_immagine(nomefile, dimensione_massima=None):\n",
    "    immagine = PIL.Image.open(nomefile)\n",
    "    \n",
    "    if dimensione_massima is not None:\n",
    "        #calcolo del fattore per il rescaling dell'immagine volto a mantenere le \n",
    "        #proporzioni tra altezza e larghezza\n",
    "        fattore_rescaling = dimensione_massima / np.max(immagine.size)\n",
    "\n",
    "        dimensione = np.array(immagine.size) * fattore_rescaling\n",
    "        dimensione = dimensione.astype(int)\n",
    "\n",
    "        immagine = immagine.resize(dimensione, PIL.Image.LANCZOS)\n",
    "    \n",
    "    return np.float32(immagine)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salva_immagine(immagine, nomefile):\n",
    "    \n",
    "    immagine = np.clip(immagine, 0.0, 255.0)\n",
    "    \n",
    "    immagine = immagine.astype(np.uint8)\n",
    "    \n",
    "    with open(nomefile, \"wb\") as file:\n",
    "        PIL.Image.fromarray(immagine).save(file, 'jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostra_immagine(immagine):\n",
    "    \n",
    "    immagine = np.clip(immagine, 0.0, 255.0)\n",
    "    \n",
    "    immagine = immagine.astype(np.uint8)\n",
    "    \n",
    "    display(PIL.Image.fromarray(immagine))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNZIONI PER IL CALCOLO DELLA PERDITA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(x, y):\n",
    "    return tf.reduce_mean(tf.square(x-y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALCOLO PERDITA CONTENUTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcola_perdita_contenuto(sessione, modello, immagine_contenuto, id_strati):\n",
    "    \n",
    "    feed_dict = modello.crea_feed_dict(immagine=immagine_contenuto)\n",
    "    \n",
    "    strati = modello.get_tensori_strati(id_strati)\n",
    "    \n",
    "    valori = sessione.run(strati, feed_dict=feed_dict)\n",
    "    \n",
    "    with modello.graph.as_default():\n",
    "        \n",
    "        perdite_strati = []\n",
    "        \n",
    "        for valore, strato in zip(valori, strati):\n",
    "            \n",
    "            costante_valore = tf.constant(valore)\n",
    "            \n",
    "            perdita = MSE(strato, costante_valore)\n",
    "            \n",
    "            perdite_strati.append(perdita)\n",
    "            \n",
    "        perdita_totale = tf.reduce_mean(perdite_strati)\n",
    "        \n",
    "    return perdita_totale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MATRICE GRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrice_gram(tensore):\n",
    "    \n",
    "    shape = tensore.get_shape()\n",
    "    \n",
    "    numero_canali = int(shape[3])\n",
    "    \n",
    "    matrice = tf.reshape(tensore, shape=[-1, numero_canali])\n",
    "    \n",
    "    gramiana = tf.matmul(tf.transpose(matrice), matrice)\n",
    "    \n",
    "    return gramiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALCOLO PERDITA STILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcola_perdita_stile(sessione, modello, immagine_stile, id_strati):\n",
    "    \n",
    "    feed_dict = modello.crea_feed_dict(immagine = immagine_stile)\n",
    "    \n",
    "    strati = modello.get_tensori_strati(id_strati)\n",
    "    \n",
    "    with modello.graph.as_default():\n",
    "        \n",
    "        strati_gram = [matrice_gram(strato) for strato in strati]\n",
    "        \n",
    "        valori = sessione.run(strati_gram, feed_dict=feed_dict)\n",
    "        \n",
    "        perdite_strati = []\n",
    "        \n",
    "        for valore, strato_gram in zip(valori, strati_gram):\n",
    "            \n",
    "            costante_valore = tf.constant(valore)\n",
    "            \n",
    "            perdita = MSE(strato_gram, costante_valore)\n",
    "            \n",
    "            perdite_strati.append(perdita)\n",
    "            \n",
    "        perdita_totale = tf.reduce_mean(perdite_strati)\n",
    "        \n",
    "    return perdita_totale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STYLE TRANSFER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_transfer(immagine_contenuto, immagine_stile, id_strati_contenuto, \n",
    "                   id_strati_stile, peso_contenuto=1.5, peso_stile=10.0,\n",
    "                   minuti=60, passo=10.0):\n",
    "    \n",
    "    ora = time.time()\n",
    "    \n",
    "    timeout = time.time() + 60*minuti\n",
    "    \n",
    "    modello = VGG16()\n",
    "    \n",
    "    sessione = tf.InteractiveSession(graph=modello.graph)\n",
    "    \n",
    "    print(\"Ora inizio: \"+str(ora))\n",
    "    \n",
    "    print(\"INZIO ALGORITMO STYLE TRANSFER\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "    print()\n",
    "    print(\"IMMAGINE CONTENUTO:\")\n",
    "    mostra_immagine(immagine_contenuto)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    print()\n",
    "    print(\"IMMAGINE STILE:\")\n",
    "    mostra_immagine(immagine_stile)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    perdita_contenuto = calcola_perdita_contenuto(sessione=sessione,\n",
    "                                                  modello=modello,\n",
    "                                                  immagine_contenuto=immagine_contenuto,\n",
    "                                                  id_strati=id_strati_contenuto)\n",
    "    \n",
    "    perdita_stile = calcola_perdita_stile(sessione=sessione, modello=modello,\n",
    "                                         immagine_stile=immagine_stile,\n",
    "                                         id_strati=id_strati_stile)\n",
    "    \n",
    "    #inizializzate a valori prossimi allo 0\n",
    "    agg_contenuto = tf.Variable(1e-10, name='agg_contenuto')\n",
    "    agg_stile = tf.Variable(1e-10, name='agg_stile')\n",
    "    \n",
    "    #inizializza variabili\n",
    "    sessione.run([agg_contenuto.initializer,\n",
    "                 agg_stile.initializer])\n",
    "    \n",
    "    #la somma ha lo scopo di evitare divisioni per zero\n",
    "    aggiorna_agg_contenuto = agg_contenuto.assign(1.0 / (perdita_contenuto + 1e-10))\n",
    "    aggiorna_agg_stile = agg_stile.assign(1.0 / (perdita_stile + 1e-10))\n",
    "\n",
    "    perdita_complessiva = peso_contenuto * agg_contenuto * perdita_contenuto + \\\n",
    "                          peso_stile * agg_stile * perdita_stile\n",
    "    \n",
    "    gradiente = tf.gradients(perdita_complessiva, modello.input)\n",
    "    \n",
    "    run_lista = [gradiente, aggiorna_agg_contenuto, aggiorna_agg_stile]\n",
    "    \n",
    "    #randomizzazione\n",
    "    immagine_risultato = np.random.rand(*immagine_contenuto.shape) + 128\n",
    "    \n",
    "    #VERSIONE BASATA SU CONVERGENZA\n",
    "    #total_loss_log = [[sys.maxsize, sys.maxsize]]\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        inizio = time.time()\n",
    "        \n",
    "        feed_dict = modello.crea_feed_dict(immagine=immagine_risultato)\n",
    "        \n",
    "        grad, valore_agg_contenuto, valore_agg_stile = sessione.run(run_lista, feed_dict=feed_dict)\n",
    "        \n",
    "        #Rimuove entry monodimensionali dalla shape di un array.\n",
    "        grad = np.squeeze(grad)\n",
    "        \n",
    "        passo_scalato = passo/ (np.std(grad) + 1e-8)\n",
    "        \n",
    "        immagine_risultato -= grad*passo_scalato\n",
    "        \n",
    "        immagine_risultato = np.clip(immagine_risultato, 0.0, 255.0)\n",
    "        \n",
    "        fine = time.time()\n",
    "        \n",
    "        trascorso = fine - inizio\n",
    "        \n",
    "        print()\n",
    "        print(\"Iterazione \"+str(i)+\" completata in \"+str(trascorso)+\" secondi\")\n",
    "        print('Perdita Stile: {} Perdita Contenuto: {}'.format(valore_agg_stile, valore_agg_contenuto))\n",
    "\n",
    "        if (i % 10 == 0):\n",
    "            \n",
    "            print()\n",
    "            print(\"Risultato dopo \"+str(i)+\" iterazioni: \")\n",
    "            mostra_immagine(immagine_risultato)\n",
    "            \n",
    "        #total_loss_log.append([valore_agg_stile, valore_agg_contenuto])\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        #print((total_loss_log[-1][0]-total_loss_log[-2][0]) + abs(total_loss_log[-1][1]-total_loss_log[-2][1])*pow(10,11))\n",
    "        #if (abs(total_loss_log[-1][0]-total_loss_log[-2][0]) + abs(total_loss_log[-1][1]-total_loss_log[-2][1]))*pow(10,11) < precisione and i > 2:\n",
    "            \n",
    "        #    break\n",
    "        \n",
    "        print(\"Tempo totale trascorso: \"+str(fine-ora)+\" secondi\")\n",
    "        \n",
    "        if time.time() > timeout:\n",
    "            \n",
    "            break\n",
    "    \n",
    "    sessione.close()\n",
    "    \n",
    "    return immagine_risultato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_immagine_contenuto = \"immagini/erika.jpg\"\n",
    "immagine_contenuto = carica_immagine(file_immagine_contenuto, dimensione_massima=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_immagine_stile = \"immagini/notte.jpg\"\n",
    "immagine_stile = carica_immagine(file_immagine_stile, dimensione_massima=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_strato_contenuto = [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_strati_stile = list(range(13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "opera = style_transfer(immagine_contenuto, immagine_stile,\n",
    "                   id_strato_contenuto, id_strati_stile,\n",
    "                   peso_contenuto=1.5, peso_stile=10.0,\n",
    "                   minuti=60, passo=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.init()\n",
    "pygame.mixer.music.load('squillo.mp3')\n",
    "pygame.mixer.music.play(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygame.mixer.music.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_immagine = \"opera\"\n",
    "mostra_immagine(opera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"opere\"):\n",
    "    os.makedirs(\"opere\")\n",
    "\n",
    "nome_opera = \"opera\"\n",
    "salva_immagine(opera, \"opere/\"+nome_opera)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
