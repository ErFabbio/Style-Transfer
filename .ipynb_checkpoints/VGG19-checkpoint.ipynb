{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as trasforma\n",
    "import torchvision.models as modelli\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import pygame\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# USARE CUDA SE DISPONIBILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_cuda = torch.cuda.is_available()\n",
    "dtype = torch.cuda.FloatTensor if usa_cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANIPOLAZIONE IMMAGINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensione_immagine = 1024 if usa_cuda else 512\n",
    "\n",
    "manipolazione = trasforma.Compose([\n",
    "    trasforma.Resize((dimensione_immagine,dimensione_immagine)),\n",
    "    trasforma.ToTensor()\n",
    "])\n",
    "\n",
    "def carica_immagine(nome_immagine):\n",
    "    immagine = Image.open(nome_immagine)\n",
    "    immagine = Variable(manipolazione(immagine))\n",
    "    #Aggiunge una dimensione al tensore\n",
    "    immagine = immagine.unsqueeze(0)\n",
    "    return immagine\n",
    "\n",
    "immagine_contenuto = carica_immagine(\"immagini/erika.jpg\").type(dtype)\n",
    "immagine_stile = carica_immagine(\"immagini/notte.jpg\").type(dtype)\n",
    "\n",
    "assert immagine_contenuto.size() == immagine_stile.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "riottieni_immagine = trasforma.ToPILImage() \n",
    "\n",
    "if not os.path.exists(\"immagini_esecuzione\"):\n",
    "    os.makedirs(\"immagini_esecuzione\")\n",
    "\n",
    "#Attiva modalitÃ  interattiva\n",
    "plt.ion()\n",
    "\n",
    "def mostra_immagine(tensore, titolo):\n",
    "    immagine = tensore.clone().cpu()\n",
    "    #reshape\n",
    "    immagine = immagine.view(3, dimensione_immagine, dimensione_immagine)\n",
    "    immagine = riottieni_immagine(immagine)\n",
    "    immagine.save(\"immagini_esecuzione/\"+titolo+\".png\")\n",
    "    plt.imshow(immagine)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(titolo)\n",
    "\n",
    "plt.figure()\n",
    "mostra_immagine(immagine_contenuto.data, titolo=\"Contenuto\")\n",
    "\n",
    "plt.figure()\n",
    "mostra_immagine(immagine_stile.data, titolo=\"Stile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNZIONI PER CALCOLO PERDITA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerditaContenuto(nn.Module):\n",
    "    \n",
    "    def __init__(self, obiettivo, peso):\n",
    "        super(PerditaContenuto, self).__init__()\n",
    "        \n",
    "        self.obiettivo = obiettivo.detach()*peso\n",
    "        self.peso = peso\n",
    "        self.criterio = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        self.perdita = self.criterio(input*self.peso, self.obiettivo)\n",
    "        self.output = input\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, retain_graph=True):\n",
    "        self.perdita.backward(retain_graph=retain_graph)\n",
    "        return self.perdita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatriceGram(nn.Module):\n",
    "\n",
    "    def forward(self, input):\n",
    "        dim_batch, num_fmaps, xfmap, yfmap = input.size()  \n",
    "\n",
    "        feature = input.view(dim_batch * num_fmaps, xfmap * yfmap)  \n",
    "\n",
    "        gramiana = torch.mm(feature, feature.t())  \n",
    "        \n",
    "        #normalizzazione valori dividendo per il numero di elementi in ogni feature map\n",
    "        return gramiana.div(dim_batch * num_fmaps * xfmap * yfmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerditaStile(nn.Module):\n",
    "\n",
    "    def __init__(self, obiettivo, peso):\n",
    "        super(PerditaStile, self).__init__()\n",
    "        self.obiettivo = obiettivo.detach() * peso\n",
    "        self.peso = peso\n",
    "        self.gramiana = MatriceGram()\n",
    "        self.criterio = nn.MSELoss()\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.output = input.clone()\n",
    "        self.G = self.gramiana(input)\n",
    "        #moltiplicazione scalare in-place\n",
    "        self.G.mul_(self.peso)\n",
    "        self.perdita = self.criterio(self.G, self.obiettivo)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, retain_graph=True):\n",
    "        self.perdita.backward(retain_graph=retain_graph)\n",
    "        return self.perdita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARICA RETE NEURALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rete = modelli.vgg19(pretrained=True).features\n",
    "\n",
    "if usa_cuda:\n",
    "    rete = rete.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strati_contenuto_selezionati = ['conv_4']\n",
    "strati_stile_selezionati = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
    "\n",
    "\n",
    "def get_stile_modello_e_perdite(rete, immagine_stile, immagine_contenuto,\n",
    "                               peso_stile=1000, peso_contenuto=1,\n",
    "                               strati_contenuto=strati_contenuto_selezionati,\n",
    "                               strati_stile=strati_stile_selezionati):\n",
    "    rete = copy.deepcopy(rete)\n",
    "\n",
    "\n",
    "    perdite_contenuto = []\n",
    "    perdite_stile = []\n",
    "    \n",
    "    #inizializzazione modello\n",
    "    modello = nn.Sequential()  \n",
    "    gramiana = MatriceGram()  \n",
    "\n",
    "    if usa_cuda:\n",
    "        modello = modello.cuda()\n",
    "        gramiana = gramiana.cuda()\n",
    "    \n",
    "    #popolazione modello\n",
    "    i = 1\n",
    "    for strato in list(rete):\n",
    "        if isinstance(strato, nn.Conv2d):\n",
    "            nome = \"conv_\" + str(i)\n",
    "            modello.add_module(nome, strato)\n",
    "\n",
    "            if nome in strati_contenuto:\n",
    "                obiettivo = modello(immagine_contenuto).clone()\n",
    "                perdita_contenuto = PerditaContenuto(obiettivo, peso_contenuto)\n",
    "                modello.add_module(\"perdita_contenuto_\" + str(i), perdita_contenuto)\n",
    "                perdite_contenuto.append(perdita_contenuto)\n",
    "\n",
    "            if nome in strati_stile:\n",
    "                obiettivo_feature = modello(immagine_stile).clone()\n",
    "                obiettivo_feature_gramiana = gramiana(obiettivo_feature)\n",
    "                perdita_stile = PerditaStile(obiettivo_feature_gramiana, peso_stile)\n",
    "                modello.add_module(\"perdita_stile_\" + str(i), perdita_stile)\n",
    "                perdite_stile.append(perdita_stile)\n",
    "\n",
    "        if isinstance(strato, nn.ReLU):\n",
    "            nome = \"relu_\" + str(i)\n",
    "            modello.add_module(nome, strato)\n",
    "\n",
    "            if nome in strati_contenuto:\n",
    "                obiettivo = modello(immagine_contenuto).clone()\n",
    "                perdita_contenuto = PerditaContenuto(obiettivo, peso_contenuto)\n",
    "                modello.add_module(\"perdita_contenuto_\" + str(i), perdita_contenuto)\n",
    "                perdite_contenuto.append(perdita_contenuto)\n",
    "\n",
    "            if nome in strati_stile:\n",
    "                obiettivo_feature = modello(immagine_stile).clone()\n",
    "                obiettivo_feature_gramiana = gramiana(obiettivo_feature)\n",
    "                perdita_stile = PerditaStile(obiettivo_feature_gramiana, peso_stile)\n",
    "                modello.add_module(\"perdita_stile_\" + str(i), perdita_stile)\n",
    "                perdite_stile.append(perdita_stile)\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        if isinstance(strato, nn.MaxPool2d):\n",
    "            nome = \"pool_\" + str(i)\n",
    "            modello.add_module(nome, strato)\n",
    "\n",
    "\n",
    "    return modello, perdite_stile, perdite_contenuto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "immagine_input = immagine_contenuto.clone()\n",
    "\n",
    "plt.figure()\n",
    "mostra_immagine(immagine_input.data, titolo='Immagine Input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISCESA DEL GRADIENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esecuzione_style_transfer(rete, immagine_contenuto, immagine_stile, immagine_input, minuti = 60,\n",
    "                       peso_stile=1000, peso_contenuto=1):\n",
    "    \n",
    "    inizio = time.time()\n",
    "    timeout = time.time()+60*minuti\n",
    "    \n",
    "    print('Costruzione modello in corso...')\n",
    "    modello, perdite_stile, perdite_contenuto = get_stile_modello_e_perdite(rete,\n",
    "        immagine_stile, immagine_contenuto, peso_stile, peso_contenuto)\n",
    "    \n",
    "    \n",
    "    parametri_input = nn.Parameter(immagine_input.data)\n",
    "    ottimizzatore = optim.LBFGS([parametri_input])\n",
    "\n",
    "    print('Ottimizzazione in corso...')\n",
    "    esecuzione = [0]\n",
    "    #VERSIONE BASATA SULLA CONVERGENZA\n",
    "    #loss_log = [[sys.maxsize,sys.maxsize], [sys.maxsize-1,sys.maxsize-1]]\n",
    "    #i = 0\n",
    "    #while abs(loss_log[-2][0]-loss_log[-1][0])+abs(loss_log[-2][1]-loss_log[-1][1]) > precisione or i<2\n",
    "    while time.time() < timeout :\n",
    "        \n",
    "        def avvicinamento():\n",
    "\n",
    "            parametri_input.data.clamp_(0, 1)\n",
    "            \n",
    "            #setta i gradienti di tutti i parametri del modello a 0\n",
    "            ottimizzatore.zero_grad()\n",
    "            modello(parametri_input)\n",
    "            score_stile = 0\n",
    "            score_contenuto = 0\n",
    "\n",
    "            for ps in perdite_stile:\n",
    "                score_stile += ps.backward()\n",
    "            for pc in perdite_contenuto:\n",
    "                score_contenuto += pc.backward()\n",
    "\n",
    "            esecuzione[0] += 1\n",
    "            #ridondante ma mi accerto che tutto fili liscio\n",
    "            print(\"Sto eseguendo...\")\n",
    "\n",
    "            print(\"esecuzione {}:\".format(esecuzione))\n",
    "            print('Perdita Stile: {:4f} Perdita Contenuto: {:4f}'.format(score_stile.data[0], score_contenuto.data[0]))\n",
    "            print(\"Tempo totale trascorso: \"+str(time.time()-inizio)+\" secondi\")\n",
    "            print()\n",
    "            \n",
    "            #loss_log.append([score_stile.data[0],score_contenuto.data[0]])\n",
    "            \n",
    "            return score_stile + score_contenuto\n",
    "        \n",
    "        ottimizzatore.step(avvicinamento)\n",
    "        \n",
    "        #i += 1\n",
    "        \n",
    "    parametri_input.data.clamp_(0, 1)\n",
    "\n",
    "    return parametri_input.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESECUZIONE ALGORITMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "opera = esecuzione_style_transfer(rete, immagine_contenuto, immagine_stile, immagine_input)\n",
    "\n",
    "plt.figure()\n",
    "mostra_immagine(opera, titolo=\"Risultato Ottenuto\")\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()\n",
    "pygame.init()\n",
    "#Squilla quando ha finito\n",
    "pygame.mixer.music.load('squillo.mp3')\n",
    "pygame.mixer.music.play(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pygame.mixer.music.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
